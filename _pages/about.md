---
permalink: /
title: About Me
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a final-year PhD candidate at the University of Alberta, supervised by Dr. A. Rupam Mahmood and Dr. Dale Schuurmans. 

I'm currently developing verifiable coding agents that can formally guarantee alignment between agent behaviour and user intentions. This trend of work targets a fundamental challenge in AI safety: ensuring that autonomous systems execute tasks transparently, without unexpected or unverified behaviours.

I used to work on effectively using data for reinforcement learning. I design and analyze algorithms that leverage datasets experiencing distribution shifts and investigate how data should be collected. My research philosophy centers on understanding empirical problems from a theoretical perspective and guiding algorithm design with theoretical insights. 

News
======

2025.10: Fengdi received the Verna Tate Graduate Scholarship in Science and began her internship at Netflix in Bay area!

2025.02: Our tutorial "Advancing Offline Reinforcement Learning: Essential Theories and Techniques for Algorithm Developers" is accepted at AAAI 2025, Philadelphia, PA, hosted by Fengdi Che, Chenjun Xiao, Ming Yin, and Csaba Szepesvári!

2024.07: Our paper "Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation" is presented at ICML 24 as a spotlight paper with only a 3.5% acceptance rate.

Key Publications
======

<div style="margin-bottom: 50px; max-width: 900px; margin-left: auto; margin-right: auto;">
  <div style="text-align: center; margin-bottom: 15px;">
    <img src="/images/publications/veri_pathway.pdf" alt="VeriEquivBench" style="width: 500px; max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
  </div>
  <div style="text-align: left; padding: 0 20px; font-size: 1.05em; line-height: 1.6;">
   Lingfei Zeng, <strong>Fengdi Che (Equal Contribution)</strong>, Xuhan Huang, Fei Ye, Xu Xu, Binhang Yuan, Jie Fu. <em>VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code.</em> <a href="https://arxiv.org/abs/2510.06296">Paper Link</a>. ICLR 2026 (Acceptance Rate 28%).
  </div>
</div>


<div style="margin-bottom: 50px; max-width: 900px; margin-left: auto; margin-right: auto;">
  <div style="text-align: center; margin-bottom: 15px;">
    <img src="/images/publications/reform.png" alt="Re:Form Paper" style="width: 500px; max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
  </div>
  <div style="text-align: left; padding: 0 20px; font-size: 1.05em; line-height: 1.6;">
    <strong>Veri-Code Team</strong> (Role in The Team: Equal Contribution First Author, and Project Lead). <em>Re: Form--Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny.</em> <a href="https://arxiv.org/abs/2507.16331v2">Paper Link</a>. 2025 Under Review.
  </div>
</div>

<div style="margin-bottom: 50px; max-width: 900px; margin-left: auto; margin-right: auto;">
  <div style="text-align: center; margin-bottom: 15px;">
    <img src="/images/publications/offline.png" alt="Tutorial Paper" style="width: 500px; max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
  </div>
  <div style="text-align: left; padding: 0 20px; font-size: 1.05em; line-height: 1.6;">
    <strong>Fengdi Che</strong>, Ming Yin, Chenjun Xiao, Csaba Szepesvári. <em>A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory.</em> <a href="http://arxiv.org/abs/2508.07746">Paper Link</a>. Presented at AAAI 2025.
  </div>
</div>

<div style="margin-bottom: 50px; max-width: 900px; margin-left: auto; margin-right: auto;">
  <div style="text-align: center; margin-bottom: 15px;">
    <img src="/images/publications/ottd.png" alt="Target Networks Paper" style="width: 500px; max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
  </div>
  <div style="text-align: left; padding: 0 20px; font-size: 1.05em; line-height: 1.6;">
    <strong>Fengdi Che</strong>, Chenjun Xiao, Jincheng Mei, Bo Dai, Ramki Gummadi, Oscar A Ramirez, Christopher K Harris, A Rupam Mahmood, Dale Schuurmans. <em>Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation.</em> <a href="https://arxiv.org/abs/2405.21043v1">Paper Link</a>. ICML 2024 (spotlight) (Acceptance Rate 3.5%).
  </div>
</div>

<div style="margin-bottom: 50px; max-width: 900px; margin-left: auto; margin-right: auto;">
  <div style="text-align: center; margin-bottom: 15px;">
    <img src="/images/publications/discount.png" alt="Discount Mismatch Paper" style="width: 500px; max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
  </div>
  <div style="text-align: left; padding: 0 20px; font-size: 1.05em; line-height: 1.6;">
    <strong>Fengdi Che</strong>, Gautham Vasan, Rupam Mahmood. <em>Correcting Discount-Factor Mismatch in On-Policy Policy Gradient Methods.</em> <a href="https://arxiv.org/abs/2306.13284">Paper Link</a>. ICML 2023 (Acceptance Rate 27.9%).
  </div>
</div>